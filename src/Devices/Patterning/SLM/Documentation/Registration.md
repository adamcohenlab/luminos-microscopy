# SLM Image Registration Guide

Proper registration of SLM and camera coordinates allows the user to select a specific region of the sample for stimulus using a structural image as a guide. Normally, this involves the camera taking a picture, the user selecting regions of interest on the picture, the host computer transforming the region of interest from camera coordinates to equivalent SLM coordinates, the CPU or GPU in the host computer calculating a hologram corresponding to the target image, and the SLM then displaying that hologram.

One of the key challenges for light patterning in biological imaging is the registration of the light patterning device with a structural image of the sample. To accomplish this task, the SLM projects a known image. This image is distorted by the optical path and is finally projected onto a brightly fluorescent test slide under the microscope. The camera takes a picture of a this test slide with this image projected onto it. The host computer can calculate the affine transformation that transforms the image taken in camera coordinates to the projected image in SLM coordinates. In previous versions of the lab's control software, the test image was a series of a few points and the user would need to manually select the spots on the screen in a specific order. While this is fine for a coarse calibration, it is imprecise and can be annoying if you forget in what order the spots need to be clicked. Furthermore, The limited number of projected spots greatly reduces the complexity of the transform that you can fit with confidence.

The new SLM registration code is largely contained in Transform_Cal with some parameters specified by the SLM_TCal method of the SLM_Device class. It requires no user intervention. Instead of using the "paired points" fitting method, it registers the projected image as a whole. Since the points are no longer, paired, we do lose some coarse information for severely distorted images, so the algorithm has been broken into a two step process. In the first step, matlab calculates an estimate of the affine transformation matrix using the phase correlation algorithm, which is less precise but more robust than intensity based image registration. This estimate is then fed in as an initial condition to an intensity based image registration function to produce "finaltform" which is the fit transformation between camera and SLM coordinates. This algorithm has been tested in simulation for robustness, and it is able to generate precise transformations provided that the SNR of the camera generated image is greater than ~8, which should be easy to produce using a test slide as the sample. 

Since all devices (including confocal waveform generators) can be registered to camera coordinates, the SLM_Device class also contains an optional method for generating an ROI using a reference image from a confocal scan. The affine transformation matrix is simply C'*S where C' is the inverse of the affine transformation matrix that registers the camera coordinates onto the confocal waveform coordinates and S is the affine transformation matrix that registers the camera coordinates onto the SLM coordinates.

Further improvements in precision could be gained by registering using nonlinear transformations, which can account for regionally variable distortions. While the 20 test points we use for calibration are more than enough for fitting these complex transforms, it is likely that the increase in precision will come with the tradeoff of reduced robustness.
